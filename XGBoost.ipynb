{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Feature 1 (Discrete)', 'Feature 2 (Discrete)', 'Feature 3 (Discrete)',\n",
       "       'Feature 4 (Discrete)', 'Feature 5 (Discrete)', 'Feature 6 (Discrete)',\n",
       "       'Feature 7 (Discrete)', 'Feature 8 (Discrete)', 'Feature 9',\n",
       "       'Feature 10', 'Feature 11', 'Feature 12', 'Feature 13', 'Feature 14',\n",
       "       'Feature 15', 'Feature 16', 'Feature 17', 'Feature 18',\n",
       "       'Feature 19 (Discrete)', 'Feature 20 (Discrete)',\n",
       "       'Feature 21 (Discrete)', 'Feature 22 (Discrete)',\n",
       "       'Feature 23 (Discrete)', 'Feature 24', 'Target Variable (Discrete)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "df=pd.read_csv('iith_foml_2020_train.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop(['Target Variable (Discrete)'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivangi/anaconda3/lib/python3.8/site-packages/sklearn/impute/_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp_mean = IterativeImputer(random_state=0)\n",
    "imp_mean.fit(df_copy)\n",
    "IterativeImputer(random_state=0)\n",
    "data = imp_mean.transform(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10, 12, 13, 15, 16, 22}\n"
     ]
    }
   ],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = pd.DataFrame(data).corr()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_drop = np.delete(data, [10,12,13,15,16,22],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = pd.DataFrame(np_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastcolumn_np = df.iloc[:,-1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data=np.concatenate((np_drop,lastcolumn_np), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(994, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(778, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "z = np.abs(stats.zscore(Final_data))\n",
    "df_o = Final_data[(z < 3).all(axis=1)]\n",
    "df_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Final_data[:,:-1], Final_data[:,-1], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  5.  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.  1.  0.  2.  0.  2.\n",
      "  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.  2.  0.  1.  1.  1.  0.  1.  2.\n",
      "  0.  0.  1.  2.  1.  1.  2.  1.  2.  6.  0.  0.  1.  2.  1.  1.  1.  1.\n",
      "  0.  2.  0.  1.  5.  1.  1.  2.  2.  0.  1.  5.  1.  1.  6.  0.  0.  2.\n",
      "  1.  6.  4.  1.  1.  6.  0.  0.  1.  2.  2.  1.  1.  6.  1.  2.  2.  0.\n",
      "  1.  1.  2.  6.  5.  2.  2.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  2.\n",
      "  1.  1.  0.  1.  0.  0.  1.  1.  1.  1.  5.  1.  1.  0.  0.  0.  0.  1.\n",
      "  1.  1.  1.  0.  1.  1.  1.  6.  1.  0.  2.  2.  1.  2.  6.  6.  1.  0.\n",
      "  1.  2.  1.  1.  0.  0.  1.  0.  2.  0.  0.  6.  0.  0.  1.  1.  0.  1.\n",
      "  1.  1.  0.  0.  1.  0.  1.  2.  1. 14.  1.  0.  1.  0.  0.  0.  0.  6.\n",
      "  0.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.\n",
      "  1.  6.  6.  2.  0.  1.  0.  1.  1.  0.  1.  0.  2.  0.  2.  1.  0.  0.\n",
      "  2.  6.  1.  4.  2.  1.  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.  1.  6.\n",
      "  0.  0.  0.  1.  0.  6.  5.  1.  1.  1.  1.  2.  1.  2.  1.  0.  1.  0.\n",
      "  0.  1.  1.  2.  1.  0.  1.  2.  5.  2.  0.  1.  0. 14.  2.  0.  1.  1.\n",
      "  5.  0.  0.  1.  0.  0.  1.  0.  5.  0.  1.  1.  0.  0.  1.  1.  2.  5.\n",
      "  1.  1.  2.  6.  2.  1.  1.  5.  1.  5.  1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "data_7 = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "data_7.fit(X_train, y_train)\n",
    "data_pred = data_7.predict(X_test)\n",
    "print(data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8996655518394648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, data_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=pd.read_csv('iith_foml_2020_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Feature 1 (Discrete)', 'Feature 2 (Discrete)', 'Feature 3 (Discrete)',\n",
       "       'Feature 4 (Discrete)', 'Feature 5 (Discrete)', 'Feature 6 (Discrete)',\n",
       "       'Feature 7 (Discrete)', 'Feature 8 (Discrete)', 'Feature 9',\n",
       "       'Feature 10', 'Feature 11', 'Feature 12', 'Feature 13', 'Feature 14',\n",
       "       'Feature 15', 'Feature 16', 'Feature 17', 'Feature 18',\n",
       "       'Feature 19 (Discrete)', 'Feature 20 (Discrete)',\n",
       "       'Feature 21 (Discrete)', 'Feature 22 (Discrete)',\n",
       "       'Feature 23 (Discrete)', 'Feature 24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_copy = df_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = imp_mean.transform(df_2_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_drop_2 = np.delete(data_2, [10,12,13,15,16,22],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_drop_2 = pd.DataFrame(np_drop_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0     1      2     3    4    5     6    7           8        9  \\\n",
      "0     146.0  12.0   42.0  14.0  7.0  1.0   1.0  1.0  118.004000  35693.5   \n",
      "1      35.0   0.0   12.0   5.0  0.0  0.0   1.0  0.0    0.001000    471.5   \n",
      "2    1018.0   8.0  259.0   2.0  1.0  1.0   1.0  1.0   15.190688  35774.5   \n",
      "3     383.0   7.0  117.0   5.0  1.0  1.0   1.0  1.0   53.002000  34094.1   \n",
      "4    1216.0   7.0   40.0   5.0  2.0  0.0   1.0  4.0    0.005000   1471.3   \n",
      "..      ...   ...    ...   ...  ...  ...   ...  ...         ...      ...   \n",
      "421    51.0   3.0   18.0   2.0  1.0  1.0   1.0  1.0  -86.956000  35777.2   \n",
      "422   942.0  35.0  242.0  56.0  1.0  1.0   1.0  1.0  155.985000  35775.1   \n",
      "423   954.0   3.0  245.0   2.0  1.0  0.0   1.0  3.0    0.001000    788.5   \n",
      "424  1297.0   0.0  355.0  43.0  1.0  1.0   1.0  1.0   50.005000  35776.5   \n",
      "425  1334.0   3.0  370.0   2.0  1.0  0.0  20.0  0.0    0.004000    612.4   \n",
      "\n",
      "           10      11            12     13    14    15     16       17  \n",
      "0    0.025200  4200.3   1488.304350   44.0  12.0   2.0   42.0  37384.5  \n",
      "1    0.001100   531.4   3497.552999   17.0   6.0   8.0    0.0  41465.1  \n",
      "2    0.000285  5514.2     15.040000    1.0   1.0   3.0   20.0  37826.2  \n",
      "3    0.041900  3358.4     15.040000  101.0   6.0   3.0   20.0  40277.3  \n",
      "4    0.001530   225.1      3.020000  276.0   6.0   7.0   43.0  28419.5  \n",
      "..        ...     ...           ...    ...   ...   ...    ...      ...  \n",
      "421  0.000213  2845.5     15.040000   20.0   1.0   1.0   22.0  24936.3  \n",
      "422  0.000237  2501.5     15.010000   12.0   1.0   0.0   12.0  35756.1  \n",
      "423  0.000419    45.2      5.020000   12.0   1.0  18.0  103.0  25477.2  \n",
      "424  0.000249  4869.1     15.010000  273.0  15.0   3.0    5.0  39522.2  \n",
      "425  0.000143  2800.1  44116.020000  202.0   1.0   4.0   10.0  40115.4  \n",
      "\n",
      "[426 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_drop_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  2.  1.  1.  1.  2.  1.  5.  1.  0.  1.  6.  0.  1.  2.  0.  1.  1.\n",
      "  1.  1.  5.  5.  1.  1.  0.  2.  6.  0.  1.  0.  0.  1.  1.  6.  1.  0.\n",
      "  6.  0.  0.  1.  1.  1.  1.  1.  0.  4.  1.  0.  6.  1.  2.  1.  1.  1.\n",
      "  1.  1.  6.  2.  0.  0.  1.  1.  1.  6.  1.  1.  2.  2.  1.  2.  1.  2.\n",
      "  1.  1.  6.  1.  1.  1.  1.  1.  1.  1.  0.  4.  6.  0.  1.  1.  1.  1.\n",
      "  1.  0.  2.  1.  1.  1.  0.  1.  2.  0.  1.  0.  0.  1.  1.  1.  1.  2.\n",
      "  0.  2.  1.  0.  0.  0.  0.  6.  0.  1.  2.  1.  0.  1.  1.  1.  6.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  0.  0.  2.  2.  2.  1.  0.  0.  1.  0.  2.\n",
      "  1.  1.  6.  2.  2.  0.  1.  1.  6.  1.  1.  1.  1.  0.  1.  1.  0.  1.\n",
      "  0.  0.  2.  1.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.\n",
      "  2.  1.  1.  1.  2.  1.  1.  2.  4.  1.  5.  0.  1.  6.  1.  1.  0.  2.\n",
      "  1.  1.  1.  0.  1.  6.  1.  1.  1.  0.  1. 14.  0.  0.  0.  0.  2.  1.\n",
      "  1.  0.  1.  1.  1.  1.  0.  1.  1.  6.  1.  1.  0.  1.  2.  1.  1.  1.\n",
      "  1.  0.  1.  1.  0.  0.  0.  1.  1.  2.  6.  5.  1.  6.  0.  1.  0.  2.\n",
      "  1.  1.  1.  2.  0.  0.  0.  1.  6.  1.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  5.  6.  0.  0.  3.  1.  1.  1.  1.  1.  5.  1.  2.  1.\n",
      "  0.  1.  0.  1.  1.  6.  0.  5.  0.  1. 14.  5.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  6.  1.  2.  1.  2.  0.  1.  1.  0.  1.  2.  1.  1.  1.  0.  0.\n",
      "  1.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.\n",
      "  1.  1.  0.  2.  0.  0.  1.  1.  1.  1.  2.  1.  1.  1.  0.  6.  2.  6.\n",
      "  2.  1.  2.  0.  6.  0.  1.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.\n",
      "  0.  1.  5.  1.  2.  1.  1.  0.  2.  1.  1.  1.  1.  0.  0.  2.  1.  1.\n",
      "  5.  1.  4.  2.  1.  1.  6.  2.  2.  0.  1.  1.  1.  1.  1.  1.  2.  1.\n",
      "  1.  1.  0.  2.  0.  1.  0.  1.  1.  1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "data_pred = data_7.predict(df_drop_2)\n",
    "print(data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(data_pred)\n",
    "df_pred.to_csv('Pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_bayes = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_copy_bayes['Target Variable (Discrete)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_copy_bayes.drop(['Target Variable (Discrete)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bo_tune_xgb(max_depth, gamma ,learning_rate):\n",
    "     params = {'max_depth': int(max_depth),\n",
    "              'gamma': gamma,\n",
    "              'learning_rate':learning_rate,\n",
    "              'subsample': 0.8,\n",
    "              'eta': 0.1,\n",
    "              'eval_metric': 'rmse'}\n",
    "    #Cross validating with the specified parameters in 5 folds and 70 iterations\n",
    "     cv_result = xgb.cv(params, dtrain, num_boost_round=70, nfold=5)\n",
    "    #Return the negative RMSE\n",
    "     return -1.0 * cv_result['test-rmse-mean'].iloc[-1]\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   gamma   | learni... | max_depth |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.994   \u001b[0m | \u001b[0m 0.7582  \u001b[0m | \u001b[0m 0.8876  \u001b[0m | \u001b[0m 4.204   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-1.853   \u001b[0m | \u001b[95m 0.2461  \u001b[0m | \u001b[95m 0.4143  \u001b[0m | \u001b[95m 8.072   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.881   \u001b[0m | \u001b[0m 0.3966  \u001b[0m | \u001b[0m 0.3894  \u001b[0m | \u001b[0m 8.681   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.97    \u001b[0m | \u001b[0m 0.7135  \u001b[0m | \u001b[0m 0.6449  \u001b[0m | \u001b[0m 4.238   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.048   \u001b[0m | \u001b[0m 0.6788  \u001b[0m | \u001b[0m 0.7299  \u001b[0m | \u001b[0m 7.287   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.931   \u001b[0m | \u001b[0m 0.4653  \u001b[0m | \u001b[0m 0.7856  \u001b[0m | \u001b[0m 3.851   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-1.809   \u001b[0m | \u001b[95m 0.4922  \u001b[0m | \u001b[95m 0.301   \u001b[0m | \u001b[95m 5.797   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.846   \u001b[0m | \u001b[0m 0.5453  \u001b[0m | \u001b[0m 0.2845  \u001b[0m | \u001b[0m 3.238   \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-1.797   \u001b[0m | \u001b[95m 0.3842  \u001b[0m | \u001b[95m 0.06419 \u001b[0m | \u001b[95m 5.666   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.818   \u001b[0m | \u001b[0m 0.04196 \u001b[0m | \u001b[0m 0.2388  \u001b[0m | \u001b[0m 5.682   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-2.661   \u001b[0m | \u001b[0m 0.3023  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.984   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-1.87    \u001b[0m | \u001b[0m 0.2947  \u001b[0m | \u001b[0m 0.4407  \u001b[0m | \u001b[0m 4.743   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-2.017   \u001b[0m | \u001b[0m 0.3132  \u001b[0m | \u001b[0m 0.8049  \u001b[0m | \u001b[0m 3.068   \u001b[0m |\n",
      "=============================================================\n",
      "{'gamma': 0.3841872139373117, 'learning_rate': 0.06418712363871505, 'max_depth': 5.6657235258612655}\n"
     ]
    }
   ],
   "source": [
    "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (3, 10),\n",
    "                                             'gamma': (0, 1),\n",
    "                                             'learning_rate':(0,1)                          \n",
    "                                            })\n",
    "xgb_bo.maximize(n_iter=5, init_points=8, acq='ei')\n",
    "#Extracting the best parameters\n",
    "params = xgb_bo.max['params']\n",
    "print(params)\n",
    "\n",
    "#Converting the max_depth and n_estimator values from float to int\n",
    "params['max_depth']= int(params['max_depth'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:53] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       251\n",
      "           1       1.00      1.00      1.00       489\n",
      "           2       1.00      0.98      0.99       111\n",
      "           3       0.67      1.00      0.80         2\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       0.98      1.00      0.99        40\n",
      "           6       1.00      1.00      1.00        70\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       0.50      1.00      0.67         1\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       1.00      1.00      1.00         4\n",
      "          16       1.00      1.00      1.00         1\n",
      "          17       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.99       994\n",
      "   macro avg       0.84      0.89      0.86       994\n",
      "weighted avg       1.00      0.99      1.00       994\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivangi/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "classifier2 = XGBClassifier(**params).fit(x,y)\n",
    "\n",
    "#predicting for training set\n",
    "train_p2 = classifier2.predict(x)\n",
    "\n",
    "#Looking at the classification report\n",
    "print(classification_report(train_p2, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_p2 = classifier2.predict(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  0  1  1  1  2  1  5  1  0  1  6  0  1  2  0  1  1  1  1  5  5  1  1\n",
      "  0  0  6  0  1  0  0  1  1  6  1  0  6  0  0  1  1  1  1  1  0  4  1  0\n",
      "  6  1  1  1  1  1  1  1  6  2  0  0  1  1  1  6  1  1  2  2  1  2  1  2\n",
      "  1  1  6  1  1  1  1  1  1  1  0  4  6  0  1  1  1  1  1  0  2  1  1  1\n",
      "  0  1  2  0  1  0  0  1  1  1  1  1  0  2  1  0  0  0  0  6  0  1  2  1\n",
      "  0  1  1  1  6  1  1  1  1  1  1  1  1  0  0  2  2  2  1  0  0  1  0  2\n",
      "  1  1  6  5  2  0  1  1  6  1  1  1  1  0  1  1  0  1  0  0  2  1  0  0\n",
      "  0  1  0  0  1  1  1  1  1  1  0  0  2  5  1  1  2  1  1  2  1  1  5  0\n",
      "  4  6  1  1  0  1  1  1  1  0  1  6  1  1  1  0  1 14  0  0  0  0  2  1\n",
      "  1  0  1  1  1  1  0  1  1  6  1  1  0  1  2  1  1  1  1  0  1  1  0  0\n",
      "  0  1  1  2  6  5  1  6  0  1  0  5  1  1  1  2  0  0  0  1  6  1  1  0\n",
      "  0  0  0  0  0  0  0  0  1  2  5  6  0  0  4  1  1  1  1  5  5  1  2  1\n",
      "  0  1  0  1  1  6  0  5  0  1 14  2  1  1  1  1  2  1  1  1  6  1  2  1\n",
      "  1  0  1  1  5  1  2  1  1  1  0  0  1  0  1  0  1  1  0  0  1  1  1  1\n",
      "  1  1  1  1  0  1  1  1  0  2  0  0  1  1  1  1  2  1  1  1  0  6  2  6\n",
      "  2  1  2  0  6  0  1  0  1  0  1  1  1  1  0  1  1  1  0  1  5  1  2  1\n",
      "  1  0  2  1  1  1  1  0  0  2  1  1  5  1  1  2  1  1  6  2  1  0  1  1\n",
      "  1  1  1  1  2  1  1  1  0  1  0  1  0  1  1  1  1  0]\n"
     ]
    }
   ],
   "source": [
    "print(predict_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_p2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_2 = pd.DataFrame(predict_p2)\n",
    "df_pred_2.to_csv('Pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
